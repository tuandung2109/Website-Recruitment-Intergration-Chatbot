import sys
import os
from pathlib import Path

# Add the backend directory to Python path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from mcp.server.fastmcp import FastMCP
from pymongo import MongoClient
from typing import List, Dict, Any
from setting import Settings


# 1Ô∏è‚É£ T·∫°o server
server = FastMCP("demo-mcp")

# Load settings
settings = Settings.load_settings()

# connect to MongoDB (example, adjust as needed)
mongo_client = MongoClient(settings.DATABASE_HOST)
db = mongo_client[settings.DATABASE_NAME]

# üöÄ Preload models ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô response
print("üöÄ Initializing models...")
from tool.model_manager import model_manager
model_manager.preload_models()
print("‚úÖ Models preloaded successfully!")

# 2Ô∏è‚É£ ƒê·ªãnh nghƒ©a tool
@server.tool()
def hello(name: str) -> str:
    """Say hello to a user"""
    return f"Hello, {name}!"

#MongoDB
@server.tool()
def find_documents(collection: str, query: Dict[str, Any] = {}) -> List[Dict[str, Any]]:
    """
    find documents in mongoDB
    Args:
        collection: name of the collection on mongoDB
        query: fillter query (vd: {"name": "Alice"})
    """
    col = db[collection]
    docs = list(col.find(query))
    
    for d in docs:
        d["_id"] = str(d["_id"])
    return docs

# Tool tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ c√¢u h·ªèi v·ªÅ JD
@server.tool()
def extract_features_from_question(query: str, prompt_type: str) -> Dict[str, Any]:
    """
    Tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng t·ª´ c√¢u h·ªèi v·ªÅ JD
    Args:
        query: c√¢u h·ªèi c·ªßa user
        prompt_type: lo·∫°i prompt ƒë·ªÉ tr√≠ch xu·∫•t (vd: "extract_features_question_aboout_job")
    Returns:
        dict: c√°c ƒë·∫∑c tr∆∞ng ƒë√£ tr√≠ch xu·∫•t
    """
    from tool.extract_feature_question_about_jd import ExtractFeatureQuestion
    extractor = ExtractFeatureQuestion(
        model_name=os.getenv("OLLAMA_MODEL", "hf.co/Cactus-Compute/Qwen3-1.7B-Instruct-GGUF:Q4_K_M"),
        validate_response=["title", "skills", "company", "location", "experience"]
    )
    features = extractor.extract(query, prompt_type)
    return features


@server.tool()
def intent_classification(query: str) -> str:
    """
    Ph√¢n lo·∫°i intent c·ªßa c√¢u h·ªèi (s·ª≠ d·ª•ng cached models)
    Args:
        query: c√¢u h·ªèi c·ªßa user
    Returns:
        str: intent ƒë√£ ph√¢n lo·∫°i (vd: "recruitment", "salary", "company_info", ...)
    """
    from tool.model_manager import model_manager
    
    try:
        # L·∫•y semantic router t·ª´ cache
        semantic_router = model_manager.get_semantic_router()
        
        # Ph√¢n lo·∫°i intent
        print(f"\nüîç Classifying query: {query}")
        score, route_name = semantic_router.guide(query)
        print(f"‚úÖ Classification result: {route_name} (score: {score:.4f})")
        
        return route_name
        
    except Exception as e:
        print(f"‚ùå Error in intent classification: {str(e)}")
        return "unknown"

@server.tool()
def enhance_question(query: str) -> str:
    """
    N√¢ng c·∫•p c√¢u h·ªèi t·ª´ incomplete -> complete
    Args:
        query: c√¢u h·ªèi c·ªßa user
    Returns:
        str: c√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p
    """
    from tool.question_enhancer import QuestionEnhancer
    enhancer = QuestionEnhancer()
    print(f"\nC√¢u h·ªèi: '{query}'")
    info_status = enhancer.analyze_incomplete_question(query)
    missing_info = enhancer.get_priority_missing_info(info_status)
    follow_up = enhancer.generate_follow_up_question(missing_info)
        
    print(f"Th√¥ng tin thi·∫øu: {[info.value for info in missing_info]}")
    print(f"C√¢u h·ªèi follow-up: {follow_up}")
    return follow_up


@server.tool()
def get_prompt(prompt_name: str, **kwargs) -> str:
    """
    L·∫•y prompt text. N·∫øu c√≥ kwargs th√¨ format c√°c placeholder.
    V√≠ d·ª•: get_prompt("extract_features_question_aboout_job", user_input="T√¨m vi·ªác ·ªü H√† N·ªôi")
    """
    from prompt.promt_config import PromptConfig
    prompt_config = PromptConfig()
    prompt_text = prompt_config.get_prompt(prompt_name, **kwargs)
    return prompt_text

@server.tool()
def get_reflection(history: List[Dict[str, str]]) -> str:
    """
    S·ª≠ d·ª•ng Reflection ƒë·ªÉ t·ª± ƒë√°nh gi√° v√† c·∫£i thi·ªán c√¢u tr·∫£ l·ªùi
    Args:
        history: l·ªãch s·ª≠ h·ªôi tho·∫°i
        question: c√¢u h·ªèi hi·ªán t·∫°i
        max_iterations: s·ªë l·∫ßn l·∫∑p t·ªëi ƒëa ƒë·ªÉ c·∫£i thi·ªán c√¢u tr·∫£ l·ªùi
    Returns:
        str: c√¢u tr·∫£ l·ªùi ƒë√£ ƒë∆∞·ª£c c·∫£i thi·ªán
    """
    from tool.reflection import Reflection
    from llms.llm_manager import llm_manager
    
    # S·ª≠ d·ª•ng LLM Manager thay v√¨ t·∫°o instance m·ªõi
    default_url = "http://host.docker.internal:11434" if os.getenv("DOCKER_ENV") == "true" else "http://localhost:11434"
    ollama_url = os.getenv("OLLAMA_URL", default_url)
    ollama_model = os.getenv("OLLAMA_MODEL", "hf.co/Cactus-Compute/Qwen3-1.7B-Instruct-GGUF:Q4_K_M")
    
    # Reuse existing LLM instance t·ª´ manager
    llm = llm_manager.get_ollama_client(base_url=ollama_url, model_name=ollama_model)
    reflection = Reflection(llm=llm)
    
    try:
        improved_answer = reflection.__call__(history)
        if "<think>" in improved_answer:
                improved_answer = improved_answer.split("</think>")[-1].strip()
        print("Reflection completed.", {"improved_answer": improved_answer})
        return improved_answer
    except Exception as e:
        print(f"‚ùå Error in reflection process: {str(e)}")
        return "Error in reflection process."
    
@server.tool()
def search_similar_jobs(query_vector: List[float], top_k: int = 5):
    """
    T√¨m ki·∫øm c√°c JD t∆∞∆°ng t·ª± trong Qdrant d·ª±a tr√™n vector truy v·∫•n
    Args:
        query_vector: vector truy v·∫•n
        top_k: s·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
    Returns:
        list: danh s√°ch c√°c JD t∆∞∆°ng t·ª±
    """
    URL_QDRANT = settings.URL_QDRANT
    API_KEY_QDRANT = settings.API_KEY_QDRANT
    from tool.database import QDrant
    try:
        qdrant_client = QDrant(
            url=URL_QDRANT,
            api_key=API_KEY_QDRANT
        )
        results = qdrant_client.search_vectors(
            collection_name=settings.COLLECTION_JOB,
            query_vector=query_vector,
            top_k=top_k
        )
        print(f"‚úÖ Found {len(results)} similar jobs.")
        return results
    except Exception as e:
        print(f"‚ùå Error in searching similar jobs: {str(e)}")
        return []


@server.tool()
def get_companies_grouped_by_industries() -> List[Dict[str, Any]]:
    """
    L·∫•y danh s√°ch c√¥ng ty ƒë√£ ƒë∆∞·ª£c nh√≥m theo ng√†nh ngh·ªÅ t·ª´ PostgreSQL/Supabase
    Returns:
        List[Dict]: danh s√°ch c√¥ng ty v·ªõi ng√†nh ngh·ªÅ ƒë√£ nh√≥m
    """
    from tool.database.postgest import PostgreSQLClient
    
    try:
        # Kh·ªüi t·∫°o PostgreSQL client (ch·ªâ c·∫ßn Supabase)
        pg_client = PostgreSQLClient(
            url=os.getenv("SUPABASE_URL"),
            key=os.getenv("SUPABASE_ANON_KEY")
        )
        
        # L·∫•y d·ªØ li·ªáu t·ª´ procedure (ƒë√£ ƒë∆∞·ª£c gom nh√≥m)
        companies_data = pg_client.get_data_from_procedures("get_cong_ty_full", limit=1000)
        
        print(f"‚úÖ Retrieved {len(companies_data)} grouped companies")
        return companies_data
        
    except Exception as e:
        print(f"‚ùå Error getting grouped companies: {str(e)}")
        return []


@server.tool()
def upsert_companies_to_qdrant_optimized(limit: int = 100):
    """
    L·∫•y c√¥ng ty t·ª´ PostgreSQL, t·∫°o embedding v√† l∆∞u v√†o Qdrant (s·ª≠ d·ª•ng LLMManager t·ªëi ∆∞u)
    Args:
        limit: s·ªë l∆∞·ª£ng c√¥ng ty ƒë·ªÉ x·ª≠ l√Ω
    Returns:
        dict: K·∫øt qu·∫£ th√™m d·ªØ li·ªáu
    """
    from tool.database.postgest import PostgreSQLClient
    
    try:
        # ƒê·ªãnh nghƒ©a extractors
        def company_text_extractor(record: Dict[str, Any]) -> str:
            text_parts = []
            
            if record.get('ten_cong_ty'):
                text_parts.append(f"C√¥ng ty: {record['ten_cong_ty']}")
            
            if record.get('ds_nganh_nghe'):
                text_parts.append(f"Ng√†nh ngh·ªÅ: {record['ds_nganh_nghe']}")
            
            if record.get('linh_vuc'):
                text_parts.append(f"Lƒ©nh v·ª±c: {record['linh_vuc']}")
            
            if record.get('mo_ta'):
                text_parts.append(f"M√¥ t·∫£: {record['mo_ta']}")
            
            return ". ".join(text_parts)
        
        def company_id_extractor(record: Dict[str, Any]) -> str:
            return f"company_{record['ma_cong_ty']}"
        
        # Kh·ªüi t·∫°o PostgreSQL client v·ªõi Qdrant
        pg_client = PostgreSQLClient(
            url=os.getenv("SUPABASE_URL"),
            key=os.getenv("SUPABASE_ANON_KEY"),
            qdrant_url=settings.QDRANT_URL,
            qdrant_api_key=settings.QDRANT_API_KEY
        )
        
        # S·ª≠ d·ª•ng embedding method t√≠ch h·ª£p
        result = pg_client.embed_data_to_qdrant(
            procedure_name="get_cong_ty_full",
            collection_name=getattr(settings, 'COLLECTION_COMPANY', 'companies'),
            text_extractor=company_text_extractor,
            id_extractor=company_id_extractor,
            limit=limit,
            batch_size=20
        )
        
        print(f"‚úÖ Embedding completed: {result}")
        return result
        
    except Exception as e:
        print(f"‚ùå Error in optimized embedding: {str(e)}")
        return {"status": "error", "message": str(e)}


@server.tool()
def search_similar_companies_optimized(query: str, top_k: int = 5):
    """
    T√¨m ki·∫øm c√°c c√¥ng ty t∆∞∆°ng t·ª± (s·ª≠ d·ª•ng PostgreSQLClient t·ªëi ∆∞u)
    Args:
        query: vƒÉn b·∫£n t√¨m ki·∫øm
        top_k: s·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
    Returns:
        list: danh s√°ch c√°c c√¥ng ty t∆∞∆°ng t·ª±
    """
    from tool.database.postgest import PostgreSQLClient
    
    try:
        # Kh·ªüi t·∫°o client v·ªõi Qdrant
        pg_client = PostgreSQLClient(
            url=os.getenv("SUPABASE_URL"),
            key=os.getenv("SUPABASE_ANON_KEY"),
            qdrant_url=settings.QDRANT_URL,
            qdrant_api_key=settings.QDRANT_API_KEY
        )
        
        # T√¨m ki·∫øm s·ª≠ d·ª•ng method t√≠ch h·ª£p
        results = pg_client.search_similar_records(
            collection_name=getattr(settings, 'COLLECTION_COMPANY', 'companies'),
            query_text=query,
            top_k=top_k,
            score_threshold=0.4
        )
        
        print(f"‚úÖ Found {len(results)} similar companies for: '{query}'")
        return results
        
    except Exception as e:
        print(f"‚ùå Error in optimized search: {str(e)}")
        return []

# 3Ô∏è‚É£ Ch·∫°y server qua STDIO
if __name__ == "__main__":
    server.run()
